# type: RCLClient

# # Trust filtering settings
# trust_filtering:
#   enable: true
#   trust_threshold: 0.5  # Minimum trust score to be considered for aggregation

# # Personalization settings
# personalization:
#   enable: true
#   freeze_backbone: true  # Freeze the backbone network except the personalized head
#   adaptive_layer_freezing: true  # Enable adaptive freezing of model layers

# # Adaptive learning rate settings
# adaptive_lr:
#   enable: true
#   beta: 0.9  # Momentum parameter for gradient variance calculation
#   min_lr: 0.001  # Minimum learning rate
#   max_lr: 0.1  # Maximum learning rate

# # Client contrastive loss settings (from original FedRCL)
# rcl_loss:
#   temperature: 0.1
#   pairwise_euclid: true
#   lambda_penalty: 0.8
#   lambda_orthogonality: 0.0
#   pairs:
#     - name: scl
#       loss_type: "supervised"
#       contrast_mode: "all"
#       lambda_weight: 0.5
#     - name: penalty
#       loss_type: "ssl"
#       contrast_mode: "all"
#       lambda_weight: 0.5

type: "RCLClient"

# Trust filtering settings
trust_filtering:
  enable: true
  trust_threshold: 0.5  # Minimum trust score to be considered for aggregation

# Personalization settings
personalization:
  enable: true
  freeze_backbone: true  # Freeze the backbone network except the personalized head
  adaptive_layer_freezing: false  # Simplified to just freeze/unfreeze for stability

# Adaptive learning rate settings
adaptive_lr:
  enable: true
  beta: 0.1  # Factor for adaptive learning rate calculation
  min_lr: 0.001  # Minimum learning rate
  max_lr: 0.1  # Maximum learning rate

# Client contrastive loss settings (from original FedRCL)
rcl_loss:
  temperature: 0.05
  pairwise_euclid: true
  lambda_penalty: 1.0  # Increased to better prevent representation collapse
  lambda_orthogonality: 0.0
  pairs:
    - name: scl
      loss_type: "supervised"
      contrast_mode: "all"
      lambda_weight: 0.5
    - name: penalty
      loss_type: "ssl"
      contrast_mode: "all"
      lambda_weight: 0.5

